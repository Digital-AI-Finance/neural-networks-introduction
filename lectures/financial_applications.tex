\documentclass[8pt,aspectratio=169]{beamer}
\usetheme{Madrid}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{multicol}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{amssymb}

% Color definitions
\definecolor{mlblue}{RGB}{0,102,204}
\definecolor{mlpurple}{RGB}{51,51,178}
\definecolor{mllavender}{RGB}{173,173,224}
\definecolor{mllavender2}{RGB}{193,193,232}
\definecolor{mllavender3}{RGB}{204,204,235}
\definecolor{mllavender4}{RGB}{214,214,239}
\definecolor{mlorange}{RGB}{255, 127, 14}
\definecolor{mlgreen}{RGB}{44, 160, 44}
\definecolor{mlred}{RGB}{214, 39, 40}
\definecolor{mlgray}{RGB}{127, 127, 127}
\definecolor{lightgray}{RGB}{240, 240, 240}
\definecolor{midgray}{RGB}{180, 180, 180}

% Apply custom colors to Madrid theme
\setbeamercolor{palette primary}{bg=mllavender3,fg=mlpurple}
\setbeamercolor{palette secondary}{bg=mllavender2,fg=mlpurple}
\setbeamercolor{palette tertiary}{bg=mllavender,fg=white}
\setbeamercolor{palette quaternary}{bg=mlpurple,fg=white}
\setbeamercolor{structure}{fg=mlpurple}
\setbeamercolor{section in toc}{fg=mlpurple}
\setbeamercolor{subsection in toc}{fg=mlblue}
\setbeamercolor{title}{fg=mlpurple}
\setbeamercolor{frametitle}{fg=mlpurple,bg=mllavender3}
\setbeamercolor{block title}{bg=mllavender2,fg=mlpurple}
\setbeamercolor{block body}{bg=mllavender4,fg=black}

\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{itemize items}[circle]
\setbeamertemplate{enumerate items}[default]
\setbeamersize{text margin left=5mm,text margin right=5mm}

\newcommand{\bottomnote}[1]{%
\vfill
\vspace{-2mm}
\textcolor{mllavender2}{\rule{\textwidth}{0.4pt}}
\vspace{1mm}
\footnotesize
\textbf{#1}
}

\title{Financial Applications}
\subtitle{Neural Networks for Finance}
\author{Neural Networks for Finance}
\institute{BSc Lecture Series}
\date{\today}

\begin{document}

\section{Historical Context: 2012-Present}


% Slide 6: 2012 - AlexNet
\begin{frame}[t]{2012: The Deep Learning Revolution}
\begin{columns}[T]
\begin{column}{0.55\textwidth}
\textbf{AlexNet (Krizhevsky et al., 2012):}
\begin{itemize}
    \item ImageNet competition: 1.2M images, 1000 classes
    \item \textcolor{mlgreen}{\textbf{Error rate: 15.3\%}} (vs. 26.2\% second place)
    \item Deep convolutional neural network (8 layers)
\end{itemize}
\vspace{3mm}
\textbf{Why This Mattered:}
\begin{itemize}
    \item 10+ percentage points better than alternatives
    \item Proved deep learning works at scale
    \item GPU training (2x NVIDIA GTX 580)
    \item Started the deep learning ``gold rush''
\end{itemize}
\end{column}
\begin{column}{0.43\textwidth}
\begin{center}
\includegraphics[width=0.98\textwidth]{../module4_applications/charts/modern_architectures_timeline/modern_architectures_timeline.pdf}
\end{center}
\end{column}
\end{columns}

% Quantlet branding (auto-generated)
\begin{tikzpicture}[remember picture,overlay]
% Logo (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.6cm,opacity=1.0] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/modern_architectures_timeline}{\includegraphics[width=0.8cm]{../../quantlet_tools/logo/quantlet.png}}
};
% QR Code (clickable)
\node[anchor=south east,xshift=-1.3cm,yshift=0.6cm,opacity=0.8] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/modern_architectures_timeline}{\includegraphics[width=0.6cm]{../module4_applications/charts/modern_architectures_timeline/qr_code.png}}
};
% URL text (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.2cm] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/modern_architectures_timeline}{\tiny\texttt{\textcolor{gray}{modern\_architectures\_timeline}}}
};
\end{tikzpicture}

\bottomnote{AlexNet: When deep learning proved its superiority}
\end{frame}

% Slide 7: What Made Deep Learning Work?
\begin{frame}[t]{What Made Deep Learning Work?}
\textbf{Three Factors Converged in the 2010s:}
\vspace{3mm}
\begin{columns}[T]
\begin{column}{0.32\textwidth}
\textbf{1. Big Data}
\begin{itemize}
    \item ImageNet: 14M+ images
    \item Internet scale data
    \item Labeled datasets
    \item In finance: tick data, alternative data
\end{itemize}
\end{column}
\begin{column}{0.32\textwidth}
\textbf{2. GPU Computing}
\begin{itemize}
    \item Parallel matrix operations
    \item 100x speedup vs CPU
    \item CUDA programming
    \item Cloud GPU access
\end{itemize}
\end{column}
\begin{column}{0.32\textwidth}
\textbf{3. Better Algorithms}
\begin{itemize}
    \item ReLU activation
    \item Dropout regularization
    \item Batch normalization
    \item Better optimizers (Adam)
\end{itemize}
\end{column}
\end{columns}
\vspace{5mm}
\begin{center}
\textcolor{mlpurple}{\textbf{All three were necessary; none was sufficient alone}}
\end{center}
\bottomnote{The convergence of data, compute, and algorithms}
\end{frame}

% Slide 8: 2017 - Transformers
\begin{frame}[t]{2017: Attention Is All You Need}
\begin{columns}[T]
\begin{column}{0.55\textwidth}
\textbf{The Transformer Architecture (Vaswani et al., 2017):}
\begin{itemize}
    \item Originally for machine translation
    \item Key innovation: \textcolor{mlblue}{\textbf{Self-attention mechanism}}
    \item No recurrence needed $\rightarrow$ parallelizable
\end{itemize}
\vspace{3mm}
\textbf{Self-Attention Intuition:}
\begin{itemize}
    \item Each position ``attends'' to all other positions
    \item Learns which inputs are relevant to each other
    \item ``The cat sat on the mat because \textit{it} was tired''
    \item Attention reveals that ``it'' refers to ``cat''
\end{itemize}
\end{column}
\begin{column}{0.43\textwidth}
\textbf{Attention Formula:}
$$\text{Attention}(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$
\vspace{3mm}
\begin{itemize}
    \item $Q$: Query (what am I looking for?)
    \item $K$: Key (what do I have?)
    \item $V$: Value (what do I return?)
\end{itemize}
\end{column}
\end{columns}
\bottomnote{Vaswani et al.: The architecture that changed everything}
\end{frame}

% Slide 9: GPT Era
\begin{frame}[t]{2020+: The GPT Era}
\textbf{Scaling Laws and Foundation Models:}
\vspace{3mm}
\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{Key Developments:}
\begin{itemize}
    \item GPT-2 (2019): 1.5B parameters
    \item GPT-3 (2020): 175B parameters
    \item GPT-4 (2023): rumored 1T+ parameters
    \item ChatGPT: Conversational interface
\end{itemize}
\vspace{3mm}
\textbf{Scaling Discovery:}
\begin{itemize}
    \item Performance scales predictably with:
    \begin{itemize}
        \item Model size
        \item Dataset size
        \item Compute budget
    \end{itemize}
\end{itemize}
\end{column}
\begin{column}{0.48\textwidth}
\textbf{Impact on Finance:}
\begin{itemize}
    \item Sentiment analysis from news/social media
    \item Document understanding (10-K filings)
    \item Natural language queries for data
    \item Automated research summarization
\end{itemize}
\vspace{3mm}
\textcolor{mlred}{\textbf{But:} LLMs don't predict stock prices}
\begin{itemize}
    \item Different problem domain
    \item Time series $\neq$ language patterns
\end{itemize}
\end{column}
\end{columns}
\bottomnote{From GPT-2 to GPT-4 and beyond}
\end{frame}

% Slide 10: Discussion Question 1
\begin{frame}[t]{Discussion Question}
\begin{center}
\vspace{1.5cm}
{\Large \textit{``Why did neural networks succeed in 2012 but not in 1990?}}\\[0.5cm]
{\Large \textit{What changed?''}}
\vspace{1cm}
\begin{itemize}
    \item Was it just computing power?
    \item What role did data play?
    \item Were the algorithms fundamentally different?
    \item Could we have predicted this breakthrough?
\end{itemize}
\end{center}
\bottomnote{Think-Pair-Share: 3 minutes}
\end{frame}

% Slide 11: AI in Finance Today
\begin{frame}[t]{AI in Finance Today}
\begin{columns}[T]
\begin{column}{0.55\textwidth}
\textbf{Major Players:}
\begin{itemize}
    \item \textbf{Renaissance Technologies}
    \begin{itemize}
        \item Medallion Fund: 66\% avg. return (1988-2018)
        \item Highly secretive, physics/math PhDs
    \end{itemize}
    \item \textbf{Two Sigma}
    \begin{itemize}
        \item \$60B+ AUM
        \item Heavy ML/AI focus
    \end{itemize}
    \item \textbf{Citadel}
    \begin{itemize}
        \item Market making + hedge fund
        \item ML for high-frequency trading
    \end{itemize}
\end{itemize}
\end{column}
\begin{column}{0.43\textwidth}
\begin{center}
\includegraphics[width=0.98\textwidth]{../module4_applications/charts/ai_applications_finance/ai_applications_finance.pdf}
\end{center}
\end{column}
\end{columns}
\vspace{2mm}
\textbf{Common Applications:} Signal generation, portfolio optimization, risk management, alternative data analysis

% Quantlet branding (auto-generated)
\begin{tikzpicture}[remember picture,overlay]
% Logo (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.6cm,opacity=1.0] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/ai_applications_finance}{\includegraphics[width=0.8cm]{../../quantlet_tools/logo/quantlet.png}}
};
% QR Code (clickable)
\node[anchor=south east,xshift=-1.3cm,yshift=0.6cm,opacity=0.8] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/ai_applications_finance}{\includegraphics[width=0.6cm]{../module4_applications/charts/ai_applications_finance/qr_code.png}}
};
% URL text (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.2cm] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/ai_applications_finance}{\tiny\texttt{\textcolor{gray}{ai\_applications\_finance}}}
};
\end{tikzpicture}

\bottomnote{Renaissance, Two Sigma, Citadel: Industry adoption}
\end{frame}

% Slide 12: The Current Landscape
\begin{frame}[t]{The Current Landscape}
\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{What's Actually Working:}
\begin{itemize}
    \item Risk management and fraud detection
    \item High-frequency market making
    \item Alternative data processing
    \item Portfolio optimization
    \item Credit scoring
    \item Sentiment analysis
\end{itemize}
\end{column}
\begin{column}{0.48\textwidth}
\textbf{What's Mostly Hype:}
\begin{itemize}
    \item ``AI that beats the market consistently''
    \item Perfect stock price prediction
    \item Fully automated trading for retail
    \item ``Guaranteed returns'' from AI
\end{itemize}
\vspace{3mm}
\textcolor{mlred}{\textbf{Red Flag:}} If someone claims their AI consistently beats the market, ask why they're selling it instead of using it.
\end{column}
\end{columns}
\bottomnote{Separating reality from marketing}
\end{frame}

% ==================== SECTION 3: REGULARIZATION (Slides 13-24) ====================

\section{Financial Data Challenges}


% Slide 25: The Nature of Financial Data
\begin{frame}[t]{The Nature of Financial Data}
\textbf{Financial Data is Fundamentally Different:}
\vspace{3mm}
\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{Images/Text:}
\begin{itemize}
    \item Patterns are stable over time
    \item Cat in 2020 looks like cat in 2010
    \item English grammar doesn't change daily
    \item High signal-to-noise ratio
    \item Abundant labeled data
\end{itemize}
\end{column}
\begin{column}{0.48\textwidth}
\textbf{Financial Markets:}
\begin{itemize}
    \item Patterns change constantly
    \item Strategies that work get arbitraged away
    \item Regime changes (bull/bear/crisis)
    \item Extremely low signal-to-noise
    \item Limited history, no ``labels'' for future
\end{itemize}
\end{column}
\end{columns}
\vspace{5mm}
\textbf{Key Insight:} Success in image recognition doesn't translate to finance.\\
The problems are fundamentally different.
\bottomnote{Financial data is fundamentally different from images or text}
\end{frame}

% Slide 26: Non-Stationarity
\begin{frame}[t]{Non-Stationarity}
\begin{columns}[T]
\begin{column}{0.55\textwidth}
\textbf{Definition:}
\begin{itemize}
    \item Statistical properties change over time
    \item Mean, variance, correlations all shift
    \item Model trained on past may fail on future
\end{itemize}
\vspace{3mm}
\textbf{Causes in Finance:}
\begin{itemize}
    \item Central bank policy changes
    \item Market structure evolution (HFT, ETFs)
    \item Regulatory changes
    \item Technology disruption
    \item Global events (pandemics, wars)
\end{itemize}
\vspace{3mm}
\textbf{Implication:}
\begin{itemize}
    \item Models have ``shelf life''
    \item Need regular retraining
    \item ``What worked'' $\neq$ ``what will work''
\end{itemize}
\end{column}
\begin{column}{0.43\textwidth}
\begin{center}
\includegraphics[width=0.98\textwidth]{../module4_applications/charts/regime_changes/regime_changes.pdf}
\end{center}
\end{column}
\end{columns}

% Quantlet branding (auto-generated)
\begin{tikzpicture}[remember picture,overlay]
% Logo (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.6cm,opacity=1.0] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/regime_changes}{\includegraphics[width=0.8cm]{../../quantlet_tools/logo/quantlet.png}}
};
% QR Code (clickable)
\node[anchor=south east,xshift=-1.3cm,yshift=0.6cm,opacity=0.8] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/regime_changes}{\includegraphics[width=0.6cm]{../module4_applications/charts/regime_changes/qr_code.png}}
};
% URL text (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.2cm] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/regime_changes}{\tiny\texttt{\textcolor{gray}{regime\_changes}}}
};
\end{tikzpicture}

\bottomnote{The patterns that worked yesterday may not work tomorrow}
\end{frame}

% Slide 27: Regime Changes
\begin{frame}[t]{Regime Changes}
\textbf{Markets Switch Between Fundamentally Different Behaviors:}
\vspace{3mm}
\begin{columns}[T]
\begin{column}{0.32\textwidth}
\textbf{Bull Market:}
\begin{itemize}
    \item Upward trend
    \item Low volatility
    \item Mean reversion works
    \item Risk-on behavior
    \item Correlations low
\end{itemize}
\end{column}
\begin{column}{0.32\textwidth}
\textbf{Bear Market:}
\begin{itemize}
    \item Downward trend
    \item High volatility
    \item Momentum works
    \item Risk-off behavior
    \item Correlations spike
\end{itemize}
\end{column}
\begin{column}{0.32\textwidth}
\textbf{Crisis:}
\begin{itemize}
    \item Extreme moves
    \item ``All correlations go to 1''
    \item Historical patterns break
    \item Liquidity disappears
    \item Fat tails dominate
\end{itemize}
\end{column}
\end{columns}
\vspace{5mm}
\textbf{Challenge:} You don't know which regime you're in until it's over.\\
\textbf{Solution:} Train separate models or use regime detection.
\bottomnote{Markets switch between fundamentally different behaviors}
\end{frame}

% Slide 28: Noise and Signal
\begin{frame}[t]{Noise vs Signal}
\begin{columns}[T]
\begin{column}{0.55\textwidth}
\textbf{Signal-to-Noise Ratio (SNR):}
\begin{itemize}
    \item Daily stock returns: SNR $\approx$ 0.05
    \item Speech recognition: SNR $\approx$ 10-20
    \item \textcolor{mlred}{200-400x harder!}
\end{itemize}
\vspace{3mm}
\textbf{What This Means:}
\begin{itemize}
    \item 95\%+ of price movement is random
    \item True patterns are tiny
    \item Easy to find spurious patterns
    \item Need massive data to detect signal
\end{itemize}
\vspace{3mm}
\textbf{Example:}
\begin{itemize}
    \item Average daily return: 0.04\%
    \item Daily standard deviation: 1\%
    \item Signal = return / std = 0.04
\end{itemize}
\end{column}
\begin{column}{0.43\textwidth}
\textbf{Implications for ML:}
\begin{itemize}
    \item Models will find patterns in noise
    \item Backtests look amazing
    \item Live performance disappoints
    \item Need extreme skepticism
\end{itemize}
\vspace{3mm}
\textbf{Reality Check:}
\begin{itemize}
    \item If returns were 50\% predictable, you'd be a billionaire in months
    \item Markets are efficient enough that small edges are huge
    \item 55\% accuracy is actually impressive
\end{itemize}
\end{column}
\end{columns}
\bottomnote{Most price movement is noise, not signal}
\end{frame}

% Slide 29: Look-Ahead Bias
\begin{frame}[t]{Look-Ahead Bias}
\begin{columns}[T]
\begin{column}{0.55\textwidth}
\textbf{Definition:} Using information that wasn't available at decision time.

\vspace{3mm}
\textbf{Common Mistakes:}
\begin{itemize}
    \item Using today's adjusted close to trade at today's open
    \item Normalizing with full dataset statistics
    \item Including stocks that didn't exist yet
    \item Using restated (revised) financial data
    \item Feature engineering with future data
\end{itemize}
\vspace{3mm}
\textbf{Example:}
\begin{itemize}
    \item Train on 2020-2023
    \item Normalize: subtract mean, divide by std
    \item \textcolor{mlred}{Problem:} Mean includes 2023!
    \item In 2020, you didn't know 2023 stats
\end{itemize}
\end{column}
\begin{column}{0.43\textwidth}
\begin{center}
\includegraphics[width=0.98\textwidth]{../module4_applications/charts/look_ahead_bias/look_ahead_bias.pdf}
\end{center}
\textbf{Prevention:}
\begin{itemize}
    \item Point-in-time data
    \item Rolling normalization
    \item Careful feature engineering
\end{itemize}
\end{column}
\end{columns}

% Quantlet branding (auto-generated)
\begin{tikzpicture}[remember picture,overlay]
% Logo (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.6cm,opacity=1.0] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/look_ahead_bias}{\includegraphics[width=0.8cm]{../../quantlet_tools/logo/quantlet.png}}
};
% QR Code (clickable)
\node[anchor=south east,xshift=-1.3cm,yshift=0.6cm,opacity=0.8] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/look_ahead_bias}{\includegraphics[width=0.6cm]{../module4_applications/charts/look_ahead_bias/qr_code.png}}
};
% URL text (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.2cm] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/look_ahead_bias}{\tiny\texttt{\textcolor{gray}{look\_ahead\_bias}}}
};
\end{tikzpicture}

\bottomnote{The silent killer of backtests}
\end{frame}

% Slide 30: Survivorship Bias
\begin{frame}[t]{Survivorship Bias}
\textbf{Definition:} Only successful companies remain in the dataset.
\vspace{3mm}
\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{The Problem:}
\begin{itemize}
    \item S\&P 500 today has survivors
    \item Enron, Lehman, Bear Stearns are gone
    \item Your model never sees failures
    \item Learns patterns of survivors only
\end{itemize}
\vspace{3mm}
\textbf{Impact:}
\begin{itemize}
    \item Overstates historical returns
    \item ``Average stock returned 10\%/year''
    \item Actually includes only winners
\end{itemize}
\end{column}
\begin{column}{0.48\textwidth}
\textbf{Real Example:}
\begin{itemize}
    \item Study: ``Value stocks beat growth''
    \item Used current value stocks list
    \item Many value stocks went bankrupt
    \item True effect was much smaller
\end{itemize}
\vspace{3mm}
\textbf{Solution:}
\begin{itemize}
    \item Point-in-time constituent lists
    \item Include delisted companies
    \item Use survivorship-bias-free databases
    \item Account for delisting returns
\end{itemize}
\end{column}
\end{columns}
\bottomnote{Your dataset doesn't include the failures}
\end{frame}

% Slide 31: Discussion Question 3
\begin{frame}[t]{Discussion Question}
\begin{center}
\vspace{1cm}
{\Large \textit{``What makes financial prediction harder than image recognition?''}}
\vspace{1cm}
\begin{itemize}
    \item A cat is always a cat. Is a bull market always a bull market?
    \item ImageNet has 14 million labeled images. How many ``market crashes'' exist?
    \item If everyone uses the same model, what happens?
    \item Does finding patterns in finance make them disappear?
\end{itemize}
\end{center}
\bottomnote{Think-Pair-Share: 3 minutes}
\end{frame}

% Slide 32: Data Preprocessing
\begin{frame}[t]{Data Preprocessing for Finance}
\textbf{Essential Preprocessing Steps:}
\vspace{3mm}
\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{Normalization:}
\begin{itemize}
    \item Z-score: $\frac{x - \mu}{\sigma}$
    \item Use rolling window (e.g., 252 days)
    \item Never use future data!
\end{itemize}
\vspace{3mm}
\textbf{Missing Data:}
\begin{itemize}
    \item Forward fill (most common)
    \item Linear interpolation
    \item Drop if too many missing
    \item \textcolor{mlred}{Never: backward fill}
\end{itemize}
\end{column}
\begin{column}{0.48\textwidth}
\textbf{Outlier Handling:}
\begin{itemize}
    \item Winsorize at 1\%/99\% percentile
    \item Or use robust statistics (median)
    \item Don't remove outliers blindly!
    \item Crashes are real data
\end{itemize}
\vspace{3mm}
\textbf{Feature Engineering:}
\begin{itemize}
    \item Returns not prices (stationarity)
    \item Log returns for mathematical convenience
    \item Technical indicators as features
    \item Lag features appropriately
\end{itemize}
\end{column}
\end{columns}
\bottomnote{Proper preprocessing is essential}
\end{frame}

% ==================== SECTION 5: STOCK PREDICTION CASE STUDY (Slides 33-44) ====================

\section{Case Study: Stock Prediction}


% Slide 33: Case Study Introduction
\begin{frame}[t]{Case Study: S\&P 500 Direction Prediction}
\textbf{A Realistic Example from Start to Finish}
\vspace{3mm}
\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{Goal:}
\begin{itemize}
    \item Predict S\&P 500 next-day direction
    \item Binary: Up or Down?
    \item Use only information available at market close
\end{itemize}
\vspace{3mm}
\textbf{Why This Problem:}
\begin{itemize}
    \item Simple, well-defined target
    \item Abundant data
    \item Common industry problem
    \item Illustrates key challenges
\end{itemize}
\end{column}
\begin{column}{0.48\textwidth}
\textbf{Our Approach:}
\begin{enumerate}
    \item Define features and target
    \item Choose architecture
    \item Set up walk-forward validation
    \item Train and evaluate
    \item Reality check the results
\end{enumerate}
\vspace{3mm}
\textbf{Spoiler:} Results will be modest.\\
That's the honest truth about financial ML.
\end{column}
\end{columns}
\bottomnote{A realistic example from start to finish}
\end{frame}

% Slide 34: Problem Definition
\begin{frame}[t]{Problem Definition}
\begin{columns}[T]
\begin{column}{0.55\textwidth}
\textbf{Target Variable:}
$$y_t = \begin{cases} 1 & \text{if } R_{t+1} > 0 \\ 0 & \text{if } R_{t+1} \leq 0 \end{cases}$$
where $R_{t+1} = \frac{P_{t+1} - P_t}{P_t}$ is next-day return.

\vspace{3mm}
\textbf{Baseline:}
\begin{itemize}
    \item Random guess: 50\% accuracy
    \item Actual: S\&P 500 up 53\% of days (long-term)
    \item ``Always predict up'': 53\% accuracy
\end{itemize}
\vspace{3mm}
\textbf{Goal:}
\begin{itemize}
    \item Beat 53\% consistently
    \item Out-of-sample (not just backtest)
    \item After transaction costs
\end{itemize}
\end{column}
\begin{column}{0.43\textwidth}
\textbf{Data:}
\begin{itemize}
    \item Period: 2000-2023 (24 years)
    \item Frequency: Daily
    \item Samples: $\sim$6,000 trading days
\end{itemize}
\vspace{3mm}
\textbf{Important Notes:}
\begin{itemize}
    \item This is harder than it sounds
    \item Small edge = big money
    \item Markets are highly efficient
    \item Most published research overfits
\end{itemize}
\end{column}
\end{columns}
\bottomnote{Binary classification: Up or Down?}
\end{frame}

% Slide 35: Input Features
\begin{frame}[t]{Input Features}
\begin{columns}[T]
\begin{column}{0.55\textwidth}
\textbf{Technical Indicators (15 features):}
\begin{itemize}
    \item Returns: 1-day, 5-day, 20-day
    \item Moving averages: 10/50/200-day ratios
    \item Volatility: 20-day rolling std
    \item RSI (14-day), MACD
    \item Bollinger Band position
    \item Volume ratio (vs 20-day avg)
\end{itemize}
\vspace{3mm}
\textbf{Market Factors (5 features):}
\begin{itemize}
    \item VIX level and change
    \item Treasury yield (10Y)
    \item Credit spread
    \item Put/Call ratio
\end{itemize}
\end{column}
\begin{column}{0.43\textwidth}
\begin{center}
\includegraphics[width=0.98\textwidth]{../module4_applications/charts/case_study_features/case_study_features.pdf}
\end{center}
\textbf{Total: 20 input features}
\end{column}
\end{columns}
\vspace{3mm}
\textbf{Preprocessing:} Rolling z-score (252-day window), clip at $\pm$3

% Quantlet branding (auto-generated)
\begin{tikzpicture}[remember picture,overlay]
% Logo (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.6cm,opacity=1.0] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/case_study_features}{\includegraphics[width=0.8cm]{../../quantlet_tools/logo/quantlet.png}}
};
% QR Code (clickable)
\node[anchor=south east,xshift=-1.3cm,yshift=0.6cm,opacity=0.8] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/case_study_features}{\includegraphics[width=0.6cm]{../module4_applications/charts/case_study_features/qr_code.png}}
};
% URL text (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.2cm] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/case_study_features}{\tiny\texttt{\textcolor{gray}{case\_study\_features}}}
};
\end{tikzpicture}

\bottomnote{15 technical indicators + 5 market factors}
\end{frame}

% Slide 36: Architecture Choice
\begin{frame}[t]{Architecture Decision}
\begin{columns}[T]
\begin{column}{0.55\textwidth}
\textbf{Network: 20-16-8-1}
\begin{itemize}
    \item Input: 20 features
    \item Hidden 1: 16 neurons (ReLU)
    \item Hidden 2: 8 neurons (ReLU)
    \item Output: 1 neuron (Sigmoid)
\end{itemize}
\vspace{3mm}
\textbf{Why This Architecture?}
\begin{itemize}
    \item Relatively shallow (avoid overfitting)
    \item Decreasing width (funnel shape)
    \item Total parameters: $\sim$500
    \item Parameters $<<$ samples (6,000)
\end{itemize}
\vspace{3mm}
\textbf{Regularization:}
\begin{itemize}
    \item L2: $\lambda = 0.001$
    \item Dropout: 0.2 (after each hidden layer)
    \item Early stopping: patience=10
\end{itemize}
\end{column}
\begin{column}{0.43\textwidth}
\begin{center}
\includegraphics[width=0.98\textwidth]{../module4_applications/charts/case_study_architecture/case_study_architecture.pdf}
\end{center}
\end{column}
\end{columns}

% Quantlet branding (auto-generated)
\begin{tikzpicture}[remember picture,overlay]
% Logo (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.6cm,opacity=1.0] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/case_study_architecture}{\includegraphics[width=0.8cm]{../../quantlet_tools/logo/quantlet.png}}
};
% QR Code (clickable)
\node[anchor=south east,xshift=-1.3cm,yshift=0.6cm,opacity=0.8] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/case_study_architecture}{\includegraphics[width=0.6cm]{../module4_applications/charts/case_study_architecture/qr_code.png}}
};
% URL text (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.2cm] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/case_study_architecture}{\tiny\texttt{\textcolor{gray}{case\_study\_architecture}}}
};
\end{tikzpicture}

\bottomnote{Balancing model capacity with overfitting risk}
\end{frame}

% Slide 37: Training Setup
\begin{frame}[t]{Training Setup}
\textbf{Walk-Forward Validation:}
\vspace{3mm}
\begin{columns}[T]
\begin{column}{0.55\textwidth}
\textbf{Data Split:}
\begin{itemize}
    \item Training: 10 years (2,500 days)
    \item Validation: 2 years (500 days)
    \item Test: 2 years (500 days)
    \item Roll forward by 1 year, retrain
\end{itemize}
\vspace{3mm}
\textbf{Training Details:}
\begin{itemize}
    \item Optimizer: Adam (lr=0.001)
    \item Loss: Binary cross-entropy
    \item Batch size: 64
    \item Max epochs: 200
    \item Early stopping: patience=10
\end{itemize}
\end{column}
\begin{column}{0.43\textwidth}
\textbf{Walk-Forward Windows:}\\[3mm]
\begin{tabular}{ccc}
\toprule
Train & Valid & Test \\
\midrule
2000-09 & 2010-11 & 2012-13 \\
2001-10 & 2011-12 & 2013-14 \\
2002-11 & 2012-13 & 2014-15 \\
... & ... & ... \\
2010-19 & 2020-21 & 2022-23 \\
\bottomrule
\end{tabular}
\vspace{3mm}
\textbf{Total:} 10 test windows
\end{column}
\end{columns}
\bottomnote{10 years training, 2 years validation, 2 years test}
\end{frame}

% Slide 38: Training Curves
\begin{frame}[t]{Results: Training Progress}
\begin{columns}[T]
\begin{column}{0.55\textwidth}
\textbf{Typical Training Run (2010-2019 $\rightarrow$ 2022-23):}
\begin{itemize}
    \item Training loss decreases smoothly
    \item Validation loss: decreases, then flat
    \item Early stopping at epoch 45-80
    \item Gap between train/val loss: moderate
\end{itemize}
\vspace{3mm}
\textbf{Observations:}
\begin{itemize}
    \item \textcolor{mlgreen}{Good:} Not severe overfitting
    \item \textcolor{mlgreen}{Good:} Validation loss improves
    \item \textcolor{mlorange}{Moderate:} Some train-val gap
    \item Training accuracy: 58-62\%
    \item Validation accuracy: 54-56\%
\end{itemize}
\end{column}
\begin{column}{0.43\textwidth}
\begin{center}
\includegraphics[width=0.98\textwidth]{../module4_applications/charts/case_study_training/case_study_training.pdf}
\end{center}
\end{column}
\end{columns}

% Quantlet branding (auto-generated)
\begin{tikzpicture}[remember picture,overlay]
% Logo (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.6cm,opacity=1.0] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/case_study_training}{\includegraphics[width=0.8cm]{../../quantlet_tools/logo/quantlet.png}}
};
% QR Code (clickable)
\node[anchor=south east,xshift=-1.3cm,yshift=0.6cm,opacity=0.8] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/case_study_training}{\includegraphics[width=0.6cm]{../module4_applications/charts/case_study_training/qr_code.png}}
};
% URL text (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.2cm] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/case_study_training}{\tiny\texttt{\textcolor{gray}{case\_study\_training}}}
};
\end{tikzpicture}

\bottomnote{Monitoring the training process}
\end{frame}

% Slide 39: Results - Accuracy
\begin{frame}[t]{Results: Accuracy}
\begin{columns}[T]
\begin{column}{0.55\textwidth}
\textbf{Out-of-Sample Results (2012-2023):}
\begin{itemize}
    \item Average test accuracy: \textbf{54.2\%}
    \item Range across windows: 51.8\% - 56.7\%
    \item Baseline (always up): 53.1\%
    \item \textcolor{mlgreen}{Edge over baseline: +1.1\%}
\end{itemize}
\vspace{3mm}
\textbf{By Year:}
\begin{itemize}
    \item Best: 2017 (56.7\%) - low volatility
    \item Worst: 2020 (51.8\%) - COVID crash
    \item Average bull market: 55.1\%
    \item Average bear market: 52.4\%
\end{itemize}
\end{column}
\begin{column}{0.43\textwidth}
\begin{center}
\includegraphics[width=0.98\textwidth]{../module4_applications/charts/case_study_results/case_study_results.pdf}
\end{center}
\end{column}
\end{columns}
\vspace{3mm}
\textbf{Is 54.2\% good?} It depends on costs and execution...

% Quantlet branding (auto-generated)
\begin{tikzpicture}[remember picture,overlay]
% Logo (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.6cm,opacity=1.0] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/case_study_results}{\includegraphics[width=0.8cm]{../../quantlet_tools/logo/quantlet.png}}
};
% QR Code (clickable)
\node[anchor=south east,xshift=-1.3cm,yshift=0.6cm,opacity=0.8] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/case_study_results}{\includegraphics[width=0.6cm]{../module4_applications/charts/case_study_results/qr_code.png}}
};
% URL text (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.2cm] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/case_study_results}{\tiny\texttt{\textcolor{gray}{case\_study\_results}}}
};
\end{tikzpicture}

\bottomnote{54.2\% accuracy - is this good?}
\end{frame}

% Slide 40: Discussion Question 4
\begin{frame}[t]{Discussion Question}
\begin{center}
\vspace{1cm}
{\Large \textit{``If a model is 54\% accurate at predicting direction,}}\\[0.3cm]
{\Large \textit{is it profitable?''}}
\vspace{1cm}
\begin{itemize}
    \item What if each trade costs 0.1\% in fees and slippage?
    \item What if you trade once per day vs once per month?
    \item Does accuracy equal profitability?
    \item What other metrics matter?
\end{itemize}
\end{center}
\bottomnote{Think-Pair-Share: 3 minutes}
\end{frame}

% Slide 41: Beyond Accuracy
\begin{frame}[t]{Beyond Accuracy: Risk-Adjusted Returns}
\textbf{Accuracy $\neq$ Profitability}
\vspace{3mm}
\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{What Accuracy Misses:}
\begin{itemize}
    \item Size of wins vs losses
    \item 54\% accuracy with small wins, large losses = loss
    \item Timing of predictions
    \item Risk taken to achieve returns
\end{itemize}
\vspace{3mm}
\textbf{Better Metrics:}
\begin{itemize}
    \item \textbf{Sharpe Ratio}: $\frac{\text{Return} - R_f}{\text{Volatility}}$
    \item \textbf{Max Drawdown}: Largest peak-to-trough loss
    \item \textbf{Win/Loss Ratio}: Avg win / Avg loss
\end{itemize}
\end{column}
\begin{column}{0.48\textwidth}
\textbf{Our Case Study:}
\begin{itemize}
    \item Annual return: 8.2\% (vs 9.5\% buy-hold)
    \item Volatility: 12.1\% (vs 18.2\% buy-hold)
    \item Sharpe: 0.68 (vs 0.52 buy-hold)
    \item Max drawdown: 18\% (vs 34\% buy-hold)
\end{itemize}
\vspace{3mm}
\textbf{Interpretation:}
\begin{itemize}
    \item Lower return than buy-hold
    \item But much lower risk
    \item Better risk-adjusted performance
    \item Before costs!
\end{itemize}
\end{column}
\end{columns}
\bottomnote{Accuracy is not the same as profitability}
\end{frame}

% Slide 42: Transaction Costs
\begin{frame}[t]{Reality Check: Transaction Costs}
\begin{columns}[T]
\begin{column}{0.55\textwidth}
\textbf{Types of Costs:}
\begin{itemize}
    \item Commission: \$0-10 per trade (retail)
    \item Bid-ask spread: 0.01\%-0.1\%
    \item Market impact: depends on size
    \item Slippage: execution vs expected price
\end{itemize}
\vspace{3mm}
\textbf{Our Strategy:}
\begin{itemize}
    \item Trades: 252 days/year (daily)
    \item Round-trip cost: 0.1\% (conservative)
    \item Annual cost: 252 $\times$ 0.1\% = 25.2\%
    \item Gross return: 8.2\%
    \item \textcolor{mlred}{\textbf{Net return: -17\%}}
\end{itemize}
\end{column}
\begin{column}{0.43\textwidth}
\begin{center}
\includegraphics[width=0.98\textwidth]{../module4_applications/charts/transaction_costs/transaction_costs.pdf}
\end{center}
\end{column}
\end{columns}
\vspace{3mm}
\textbf{Lesson:} Daily trading requires extremely high accuracy to be profitable.

% Quantlet branding (auto-generated)
\begin{tikzpicture}[remember picture,overlay]
% Logo (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.6cm,opacity=1.0] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/transaction_costs}{\includegraphics[width=0.8cm]{../../quantlet_tools/logo/quantlet.png}}
};
% QR Code (clickable)
\node[anchor=south east,xshift=-1.3cm,yshift=0.6cm,opacity=0.8] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/transaction_costs}{\includegraphics[width=0.6cm]{../module4_applications/charts/transaction_costs/qr_code.png}}
};
% URL text (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.2cm] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/transaction_costs}{\tiny\texttt{\textcolor{gray}{transaction\_costs}}}
};
\end{tikzpicture}

\bottomnote{Costs can eliminate paper profits entirely}
\end{frame}

% Slide 43: The EMH Question
\begin{frame}[t]{The Efficient Market Hypothesis}
\begin{columns}[T]
\begin{column}{0.55\textwidth}
\textbf{EMH (Fama, 1970):}\\
``Prices fully reflect all available information''

\vspace{3mm}
\textbf{Three Forms:}
\begin{itemize}
    \item \textbf{Weak:} Can't profit from past prices
    \item \textbf{Semi-strong:} Can't profit from public info
    \item \textbf{Strong:} Can't profit from any info
\end{itemize}
\vspace{3mm}
\textbf{Implications for ML:}
\begin{itemize}
    \item If EMH true: all patterns are noise
    \item If EMH false: patterns exist but are small
    \item Reality: markets are ``mostly efficient''
    \item Small, temporary inefficiencies exist
\end{itemize}
\end{column}
\begin{column}{0.43\textwidth}
\begin{center}
\includegraphics[width=0.98\textwidth]{../module4_applications/charts/emh_visualization/emh_visualization.pdf}
\end{center}
\textbf{Grossman-Stiglitz Paradox:}\\
If markets were perfectly efficient, no one would do research, so they couldn't be efficient.
\end{column}
\end{columns}

% Quantlet branding (auto-generated)
\begin{tikzpicture}[remember picture,overlay]
% Logo (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.6cm,opacity=1.0] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/emh_visualization}{\includegraphics[width=0.8cm]{../../quantlet_tools/logo/quantlet.png}}
};
% QR Code (clickable)
\node[anchor=south east,xshift=-1.3cm,yshift=0.6cm,opacity=0.8] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/emh_visualization}{\includegraphics[width=0.6cm]{../module4_applications/charts/emh_visualization/qr_code.png}}
};
% URL text (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.2cm] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/emh_visualization}{\tiny\texttt{\textcolor{gray}{emh\_visualization}}}
};
\end{tikzpicture}

\bottomnote{Markets are (mostly) efficient}
\end{frame}

% Slide 44: Honest Assessment
\begin{frame}[t]{What Works and What Doesn't}
\begin{columns}[T]
\begin{column}{0.48\textwidth}
\textbf{What Works (Maybe):}
\begin{itemize}
    \item Risk management and hedging
    \item Alternative data processing
    \item High-frequency market making
    \item Factor model enhancement
    \item Portfolio optimization
    \item Regime detection
\end{itemize}
\vspace{3mm}
\textbf{Where NNs Add Value:}
\begin{itemize}
    \item Complex non-linear relationships
    \item High-dimensional feature spaces
    \item Alternative data (satellite, NLP)
    \item Execution optimization
\end{itemize}
\end{column}
\begin{column}{0.48\textwidth}
\textbf{What Doesn't Work:}
\begin{itemize}
    \item ``Predicting stock prices'' (directly)
    \item Black-box trading systems
    \item Complex models on small data
    \item Ignoring transaction costs
    \item Overfitting to backtests
\end{itemize}
\vspace{3mm}
\textbf{Honest Expectations:}
\begin{itemize}
    \item Small edges are valuable
    \item 55\% accuracy is impressive
    \item Risk management $>$ alpha generation
    \item Domain knowledge essential
\end{itemize}
\end{column}
\end{columns}
\bottomnote{Setting appropriate expectations for neural networks in finance}
\end{frame}

% ==================== SECTION 6: MODERN ARCHITECTURES (Slides 45-50) ====================

\end{document}
