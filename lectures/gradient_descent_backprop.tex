\documentclass[8pt,aspectratio=169]{beamer}
\usetheme{Madrid}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{multicol}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{amssymb}

% Color definitions
\definecolor{mlblue}{RGB}{0,102,204}
\definecolor{mlpurple}{RGB}{51,51,178}
\definecolor{mllavender}{RGB}{173,173,224}
\definecolor{mllavender2}{RGB}{193,193,232}
\definecolor{mllavender3}{RGB}{204,204,235}
\definecolor{mllavender4}{RGB}{214,214,239}
\definecolor{mlorange}{RGB}{255, 127, 14}
\definecolor{mlgreen}{RGB}{44, 160, 44}
\definecolor{mlred}{RGB}{214, 39, 40}
\definecolor{mlgray}{RGB}{127, 127, 127}
\definecolor{lightgray}{RGB}{240, 240, 240}
\definecolor{midgray}{RGB}{180, 180, 180}

% Apply custom colors to Madrid theme
\setbeamercolor{palette primary}{bg=mllavender3,fg=mlpurple}
\setbeamercolor{palette secondary}{bg=mllavender2,fg=mlpurple}
\setbeamercolor{palette tertiary}{bg=mllavender,fg=white}
\setbeamercolor{palette quaternary}{bg=mlpurple,fg=white}
\setbeamercolor{structure}{fg=mlpurple}
\setbeamercolor{section in toc}{fg=mlpurple}
\setbeamercolor{subsection in toc}{fg=mlblue}
\setbeamercolor{title}{fg=mlpurple}
\setbeamercolor{frametitle}{fg=mlpurple,bg=mllavender3}
\setbeamercolor{block title}{bg=mllavender2,fg=mlpurple}
\setbeamercolor{block body}{bg=mllavender4,fg=black}

\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{itemize items}[circle]
\setbeamertemplate{enumerate items}[default]
\setbeamersize{text margin left=5mm,text margin right=5mm}

\newcommand{\bottomnote}[1]{%
\vfill
\vspace{-2mm}
\textcolor{mllavender2}{\rule{\textwidth}{0.4pt}}
\vspace{1mm}
\footnotesize
\textbf{#1}
}

\title{Gradient Descent and Backpropagation}
\subtitle{Neural Networks for Finance}
\author{Neural Networks for Finance}
\institute{BSc Lecture Series}
\date{\today}

\begin{document}

\section{Opening}


% Slide 1: Title
\begin{frame}[plain]
\titlepage
\end{frame}

% Slide 2: The Central Question
\begin{frame}[t]{The Central Question}
\begin{center}
\Large
\textit{``We have the architecture. How does it LEARN?''}
\end{center}

\vspace{1em}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{What We Know:}
\begin{itemize}
\item MLP architecture (Module 2)
\item Forward pass computation
\item Loss functions measure error
\item Good weights exist (universal approximation)
\end{itemize}

\column{0.48\textwidth}
\textbf{What We Don't Know:}
\begin{itemize}
\item How to find good weights
\item How errors guide updates
\item Why training sometimes fails
\item How to avoid overfitting
\end{itemize}
\end{columns}

\vspace{0.5em}
\textcolor{mlpurple}{\textbf{This module bridges the gap from architecture to learning.}}
\bottomnote{The fundamental challenge of neural network training}
\end{frame}

% Slide 3: The Trading Desk Analogy
\begin{frame}[t]{Finance Parallel: The Trading Desk}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{How Traders Improve}

A trader's learning process:
\begin{enumerate}
\item Make a trade (forward pass)
\item Wait for P\&L (loss function)
\item Analyze what went wrong (gradient)
\item Adjust strategy (weight update)
\item Repeat thousands of times (epochs)
\end{enumerate}

\vspace{0.5em}
\textbf{Key Insight:}

Mistakes are information. Each error tells you how to adjust.

\column{0.48\textwidth}
\textbf{Neural Network Training}

\vspace{0.5em}
\begin{tabular}{ll}
\toprule
\textbf{Trading} & \textbf{Neural Net} \\
\midrule
Trade execution & Forward pass \\
P\&L calculation & Loss function \\
Post-trade analysis & Backpropagation \\
Strategy adjustment & Weight update \\
Experience & Training epochs \\
\bottomrule
\end{tabular}

\vspace{0.5em}
Both learn by \textbf{iteratively correcting mistakes}.
\end{columns}
\bottomnote{How does a trader improve? By analyzing what went wrong.}
\end{frame}

% Slide 4: Module 3 Roadmap
\begin{frame}[t]{Module 3 Roadmap}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Today's Journey}

\begin{enumerate}
\item \textbf{Loss Functions (Review)}
\begin{itemize}
\item Measuring prediction error
\item MSE intuition
\end{itemize}

\item \textbf{Gradient Descent}
\begin{itemize}
\item Finding the minimum
\item Learning rate tuning
\end{itemize}

\item \textbf{Backpropagation}
\begin{itemize}
\item Credit assignment
\item Chain rule in action
\end{itemize}
\end{enumerate}

\column{0.48\textwidth}
\begin{enumerate}
\setcounter{enumi}{3}
\item \textbf{Training Dynamics}
\begin{itemize}
\item Batch vs. stochastic
\item Epochs and convergence
\end{itemize}

\item \textbf{Overfitting}
\begin{itemize}
\item The enemy of generalization
\item The backtest trap
\end{itemize}
\end{enumerate}

\vspace{0.5em}
\textbf{Learning Objectives:}
\begin{itemize}
\item Understand gradient descent intuitively
\item Grasp backpropagation as ``blame assignment''
\item Recognize and prevent overfitting
\end{itemize}
\end{columns}
\bottomnote{From measuring error to updating weights}
\end{frame}

% Slide 5: The Learning Problem
\begin{frame}[t]{The Learning Problem}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{The Challenge}

\textbf{Given:}
\begin{itemize}
\item Training data: $\{(\mathbf{x}^{(i)}, y^{(i)})\}_{i=1}^m$
\item Network architecture
\item Loss function $\mathcal{L}$
\end{itemize}

\textbf{Find:}
\begin{itemize}
\item Weights $\mathbf{W}$ and biases $\mathbf{b}$
\item That minimize $\mathcal{L}$
\item And generalize to new data
\end{itemize}

\vspace{0.5em}
\textbf{Scale of the Problem:}

A 4-10-5-1 network: 111 parameters

A ResNet-50: 25 million parameters

\column{0.48\textwidth}
\textbf{Why Is This Hard?}

\vspace{0.5em}
\textbf{Dimensionality:}
\begin{itemize}
\item Millions of weights to tune
\item Exponentially many combinations
\item Can't try them all
\end{itemize}

\textbf{Non-Convexity:}
\begin{itemize}
\item Many local minima
\item Saddle points
\item Flat regions
\end{itemize}

\textbf{The Solution:}

Gradient-based optimization

``Move downhill in weight space''
\end{columns}
\bottomnote{Thousands of weights to tune - how do we find the right values?}
\end{frame}

% ==================== SECTION 2: HISTORICAL CONTEXT (Slides 6-10) ====================

\section{Historical Context: 1986-2012}


% Slide 6: 1989 - LeNet
\begin{frame}[t]{1989: LeNet and Practical Success}
\begin{columns}[T]
\column{0.45\textwidth}
\textbf{Yann LeCun at Bell Labs}

First commercially deployed neural network:
\begin{itemize}
\item Handwritten digit recognition
\item Used by US Postal Service
\item Read millions of checks
\item Proved neural nets could work
\end{itemize}

\vspace{0.5em}
\textbf{Key Innovations:}
\begin{itemize}
\item Convolutional architecture
\item Shared weights
\item Backprop through convolutions
\end{itemize}

\column{0.52\textwidth}
\begin{center}
\includegraphics[width=0.98\textwidth]{../module3_training/charts/timeline_1986_2012/timeline_1986_2012.pdf}
\end{center}
\end{columns}

% Quantlet branding (auto-generated)
\begin{tikzpicture}[remember picture,overlay]
% Logo (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.6cm,opacity=1.0] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/timeline_1986_2012}{\includegraphics[width=0.8cm]{../../quantlet_tools/logo/quantlet.png}}
};
% QR Code (clickable)
\node[anchor=south east,xshift=-1.3cm,yshift=0.6cm,opacity=0.8] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/timeline_1986_2012}{\includegraphics[width=0.6cm]{../module3_training/charts/timeline_1986_2012/qr_code.png}}
};
% URL text (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.2cm] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/timeline_1986_2012}{\tiny\texttt{\textcolor{gray}{timeline\_1986\_2012}}}
};
\end{tikzpicture}

\bottomnote{Yann LeCun: First commercially deployed neural network}
\end{frame}

% Slide 7: 1991 - Vanishing Gradients
\begin{frame}[t]{1991: The Vanishing Gradient Problem}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{The Discovery}

Sepp Hochreiter (1991) identified why deep networks fail:

\vspace{0.5em}
\textbf{The Problem:}
\begin{itemize}
\item Gradients multiply through layers
\item Sigmoid derivative: max 0.25
\item Through 10 layers: $0.25^{10} \approx 10^{-6}$
\item Early layers learn nothing
\end{itemize}

\vspace{0.5em}
\textbf{Symptoms:}
\begin{itemize}
\item Later layers learn quickly
\item Early layers stuck at random
\item Network never converges
\end{itemize}

\column{0.48\textwidth}
\textbf{Why Sigmoid Causes Problems}

\vspace{0.5em}
For sigmoid: $\sigma'(z) = \sigma(z)(1-\sigma(z))$

Maximum value: $\sigma'(0) = 0.25$

\vspace{0.5em}
\begin{center}
\begin{tabular}{cc}
\toprule
\textbf{Layers} & \textbf{Max Gradient} \\
\midrule
1 & 0.25 \\
5 & $10^{-3}$ \\
10 & $10^{-6}$ \\
20 & $10^{-12}$ \\
\bottomrule
\end{tabular}
\end{center}

\vspace{0.5em}
\textcolor{mlpurple}{\textbf{Implication:}} Deep networks seemed impossible until ReLU (2010).
\end{columns}
\bottomnote{Deep networks couldn't learn - gradients disappeared}
\end{frame}

% Slide 8: 1997 - LSTM
\begin{frame}[t]{1997: LSTM Networks}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Long Short-Term Memory}

Hochreiter \& Schmidhuber solution:
\begin{itemize}
\item Designed for sequences
\item Explicit ``memory'' cells
\item Gating mechanisms
\item Gradients can flow unchanged
\end{itemize}

\vspace{0.5em}
\textbf{Key Innovation:}

The ``constant error carousel'' -- a path where gradients don't decay.

\vspace{0.5em}
\textbf{Applications:}
\begin{itemize}
\item Speech recognition
\item Machine translation
\item Time series prediction
\end{itemize}

\column{0.48\textwidth}
\textbf{Finance Relevance}

\vspace{0.5em}
LSTMs became popular for:
\begin{itemize}
\item Stock price prediction
\item Volatility forecasting
\item Sentiment analysis
\item Algorithmic trading
\end{itemize}

\vspace{0.5em}
\textbf{Why LSTM for Finance?}
\begin{itemize}
\item Financial data is sequential
\item Long-term dependencies matter
\item Regime changes persist
\end{itemize}

\vspace{0.5em}
\textcolor{mlpurple}{\textbf{Note:}} Now largely replaced by Transformers (2017).
\end{columns}
\bottomnote{Hochreiter and Schmidhuber: Long Short-Term Memory}
\end{frame}

% Slide 9: 2012 - ImageNet Moment
\begin{frame}[t]{2012: The ImageNet Moment}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{AlexNet Wins ImageNet}

Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton:
\begin{itemize}
\item 15.3\% error rate
\item Second place: 26.2\%
\item \textbf{40\% relative improvement}
\item Used GPUs for training
\end{itemize}

\vspace{0.5em}
\textbf{What Made It Work:}
\begin{enumerate}
\item ReLU activation (not sigmoid)
\item Dropout regularization
\item GPU training (60x faster)
\item Large dataset (1.2M images)
\item Data augmentation
\end{enumerate}

\column{0.48\textwidth}
\textbf{Why This Was Different}

\vspace{0.5em}
\textbf{Previous Attempts:}
\begin{itemize}
\item Shallow networks
\item Hand-crafted features
\item Small datasets
\item CPU training
\end{itemize}

\textbf{AlexNet:}
\begin{itemize}
\item 8 layers deep
\item Learned features
\item Massive data
\item GPU parallelism
\end{itemize}

\vspace{0.5em}
\textcolor{mlpurple}{\textbf{The Result:}} Deep learning became the dominant paradigm. Every major AI company pivoted.
\end{columns}
\bottomnote{AlexNet: Deep learning proves its superiority}
\end{frame}

% Slide 10: What Changed?
\begin{frame}[t]{What Changed Between 1990 and 2012?}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{The Ingredients for Success}

\begin{enumerate}
\item \textbf{Big Data}
\begin{itemize}
\item ImageNet: 1.2M labeled images
\item Internet made data collection possible
\item 1990: thousands of samples
\end{itemize}

\item \textbf{Compute Power}
\begin{itemize}
\item GPUs: 100x speedup
\item Moore's law compounding
\item Training in days, not years
\end{itemize}
\end{enumerate}

\column{0.48\textwidth}
\begin{enumerate}
\setcounter{enumi}{2}
\item \textbf{Algorithmic Improvements}
\begin{itemize}
\item ReLU: no vanishing gradients
\item Dropout: better generalization
\item Batch normalization (2015)
\end{itemize}

\item \textbf{Open Research Culture}
\begin{itemize}
\item arXiv preprints
\item Open-source frameworks
\item Reproducibility
\end{itemize}
\end{enumerate}

\vspace{0.5em}
\textcolor{mlpurple}{\textbf{Key Insight:}} The core ideas from 1986 worked -- they just needed scale and engineering.
\end{columns}
\bottomnote{Big data + GPUs + ReLU + dropout = breakthrough}
\end{frame}

% ==================== SECTION 3: LOSS FUNCTIONS (Slides 11-18) ====================

\section{Loss Functions: Measuring Mistakes}


% Slide 11: What Does "Wrong" Mean?
\begin{frame}[t]{What Does ``Wrong'' Mean?}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Quantifying Prediction Error}

We need a function that:
\begin{itemize}
\item Takes predictions and labels
\item Returns a single number
\item Higher = worse predictions
\item Differentiable (for gradients)
\end{itemize}

\vspace{0.5em}
\textbf{The Loss Function:}

$$\mathcal{L}(\hat{y}, y)$$

\vspace{0.5em}
\textbf{Properties We Want:}
\begin{itemize}
\item $\mathcal{L} \geq 0$ (non-negative)
\item $\mathcal{L} = 0$ iff perfect prediction
\item Smooth (for optimization)
\end{itemize}

\column{0.48\textwidth}
\textbf{Different Tasks, Different Losses}

\vspace{0.5em}
\begin{tabular}{ll}
\toprule
\textbf{Task} & \textbf{Loss} \\
\midrule
Regression & MSE \\
Binary classification & Cross-entropy \\
Multi-class & Categorical CE \\
Ranking & Hinge loss \\
\bottomrule
\end{tabular}

\vspace{0.5em}
\textbf{Finance Examples:}
\begin{itemize}
\item Return prediction: MSE
\item Buy/sell: Binary CE
\item Sector classification: Categorical CE
\end{itemize}
\end{columns}
\bottomnote{We need a way to measure how wrong our predictions are}
\end{frame}

% Slide 12: Finance Analogy - P&L
\begin{frame}[t]{Finance Analogy: Profit and Loss}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{P\&L as a Loss Function}

For traders:
\begin{itemize}
\item P\&L = realized gain/loss
\item Negative P\&L = bad trades
\item Goal: maximize P\&L
\end{itemize}

\vspace{0.5em}
\textbf{Connection to ML Loss:}
\begin{itemize}
\item ML loss = prediction error
\item Higher loss = worse model
\item Goal: minimize loss
\end{itemize}

\vspace{0.5em}
\textbf{Key Difference:}

P\&L is a \textit{performance} metric.

ML loss is an \textit{optimization} target.

They may not align perfectly!

\column{0.48\textwidth}
\textbf{When P\&L $\neq$ Loss}

\vspace{0.5em}
A model might have:
\begin{itemize}
\item Low MSE (accurate predictions)
\item But low P\&L (wrong on big moves)
\end{itemize}

Or:
\begin{itemize}
\item High MSE (noisy predictions)
\item But high P\&L (right when it matters)
\end{itemize}

\vspace{0.5em}
\textbf{Implication:}

Consider using custom loss functions that better align with trading goals.

\vspace{0.5em}
\textcolor{mlpurple}{\textit{Module 4 explores this tension.}}
\end{columns}
\bottomnote{P\&L is the loss function of trading}
\end{frame}

% Slide 13: Loss Function Definition
\begin{frame}[t]{Loss Function: Error Measurement}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Total Loss Over Dataset}

For $m$ training examples:

$$\mathcal{L}(\mathbf{W}) = \frac{1}{m} \sum_{i=1}^{m} \ell(\hat{y}^{(i)}, y^{(i)})$$

where:
\begin{itemize}
\item $\ell$: loss per example
\item $\hat{y}^{(i)} = f(\mathbf{x}^{(i)}; \mathbf{W})$: prediction
\item $y^{(i)}$: true label
\item $\mathbf{W}$: all network weights
\end{itemize}

\vspace{0.5em}
\textbf{Goal:}

$$\mathbf{W}^* = \arg\min_{\mathbf{W}} \mathcal{L}(\mathbf{W})$$

\column{0.48\textwidth}
\textbf{Why Average?}

\vspace{0.5em}
\textbf{Sum vs Average:}
\begin{itemize}
\item Sum: scales with dataset size
\item Average: comparable across datasets
\item Gradient magnitude consistent
\end{itemize}

\vspace{0.5em}
\textbf{The Optimization Landscape:}

$\mathcal{L}(\mathbf{W})$ defines a surface over weight space.

\begin{itemize}
\item High regions: bad weights
\item Low regions: good weights
\item We seek the lowest point
\end{itemize}
\end{columns}
\bottomnote{The loss function quantifies prediction error}
\end{frame}

% Slide 14: MSE Intuition
\begin{frame}[t]{Mean Squared Error: Intuition}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{The Formula}

$$\mathcal{L}_{MSE} = \frac{1}{m} \sum_{i=1}^{m} (y^{(i)} - \hat{y}^{(i)})^2$$

\vspace{0.5em}
\textbf{In Words:}
\begin{enumerate}
\item Compute error: $y - \hat{y}$
\item Square it: $(y - \hat{y})^2$
\item Average over all samples
\end{enumerate}

\vspace{0.5em}
\textbf{Why Squaring?}
\begin{itemize}
\item Makes all errors positive
\item Penalizes large errors heavily
\item Mathematically convenient
\end{itemize}

\column{0.48\textwidth}
\textbf{Example}

\vspace{0.5em}
\begin{tabular}{ccc}
\toprule
$y$ & $\hat{y}$ & $(y-\hat{y})^2$ \\
\midrule
5\% & 3\% & 4 \\
-2\% & 1\% & 9 \\
8\% & 7\% & 1 \\
\midrule
\textbf{MSE} & & \textbf{4.67} \\
\bottomrule
\end{tabular}

\vspace{0.5em}
Units: $\text{(percentage points)}^2$

\vspace{0.5em}
\textbf{RMSE:} $\sqrt{MSE} = 2.16\%$

``On average, we're off by about 2\%''
\end{columns}
\bottomnote{``How far off were we, on average?''}
\end{frame}

% Slide 15: MSE Visually
\begin{frame}[t]{MSE: Visual Interpretation}
\begin{columns}[T]
\column{0.45\textwidth}
\textbf{Squared Errors as Areas}

Each error $(y - \hat{y})^2$ is the area of a square with side length $|y - \hat{y}|$.

\vspace{0.5em}
\textbf{MSE = Average Square Area}

\vspace{0.5em}
\textbf{Why This Matters:}
\begin{itemize}
\item Error of 4 is 16x worse than error of 1
\item Large errors dominate
\item Outliers have huge impact
\end{itemize}

\vspace{0.5em}
\textbf{Alternative: MAE}

Mean Absolute Error:
$$\mathcal{L}_{MAE} = \frac{1}{m} \sum |y - \hat{y}|$$

More robust to outliers.

\column{0.52\textwidth}
\begin{center}
\includegraphics[width=0.98\textwidth]{../module3_training/charts/mse_visualization/mse_visualization.pdf}
\end{center}
\end{columns}
\bottomnote{Squaring emphasizes large errors}
\end{frame}

% Slide 16: Finance Application
\begin{frame}[t]{Finance Application: Return Prediction}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Worked Example}

\textbf{Predictions for 5 Stocks:}

\begin{tabular}{lccc}
\toprule
\textbf{Stock} & $\hat{y}$ & $y$ & Error$^2$ \\
\midrule
AAPL & +5\% & +2\% & 9 \\
MSFT & +3\% & +4\% & 1 \\
GOOG & -1\% & +2\% & 9 \\
AMZN & +4\% & +4\% & 0 \\
META & +2\% & -3\% & 25 \\
\midrule
\textbf{MSE} & & & \textbf{8.8} \\
\bottomrule
\end{tabular}

\vspace{0.5em}
RMSE = 2.97\%

\column{0.48\textwidth}
\textbf{Interpretation}

\vspace{0.5em}
``On average, our return predictions are off by about 3 percentage points.''

\vspace{0.5em}
\textbf{Is This Good?}

Depends on context:
\begin{itemize}
\item Market daily vol: $\sim$1\%
\item 3\% RMSE = 3 std devs
\item \textcolor{mlred}{Not very predictive}
\end{itemize}

\vspace{0.5em}
\textbf{Reality Check:}

Even small predictability (RMSE slightly $<$ volatility) can be valuable in trading.
\end{columns}
\bottomnote{Worked example with stock returns}
\end{frame}

% Slide 17: Discussion Question 1
\begin{frame}[t]{Discussion Question}
\begin{center}
\Large
\textit{``Why might we want to penalize large errors more than small ones in stock prediction?''}
\end{center}

\vspace{1em}
\textbf{Consider:}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Arguments For (Use MSE):}
\begin{itemize}
\item Big errors are costlier
\item Crashes matter more than small moves
\item Position sizing affected
\item Risk management
\end{itemize}

\column{0.48\textwidth}
\textbf{Arguments Against (Use MAE):}
\begin{itemize}
\item Markets have fat tails
\item Outliers can dominate MSE
\item May optimize for rare events
\item Robustness to noise
\end{itemize}
\end{columns}

\vspace{0.5em}
\textcolor{mlpurple}{\textbf{Reality:}} Many practitioners use MAE or Huber loss (combines both) for financial applications.
\bottomnote{Think-Pair-Share: 3 minutes}
\end{frame}

% Slide 18: Loss Landscape Revisited
\begin{frame}[t]{The Loss Landscape}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Loss as a Function of Weights}

$$\mathcal{L}(\mathbf{W})$$

For every choice of weights, there's a loss value.

\vspace{0.5em}
\textbf{In 2D (two weights):}

A surface we can visualize.

\vspace{0.5em}
\textbf{In High Dimensions:}

A hypersurface we navigate blindly.

\vspace{0.5em}
\textbf{Features:}
\begin{itemize}
\item Global minimum (best)
\item Local minima (traps)
\item Saddle points
\item Flat regions (plateaus)
\end{itemize}

\column{0.48\textwidth}
\begin{center}
\includegraphics[width=0.98\textwidth]{../module3_training/charts/loss_landscape_3d/loss_landscape_3d.pdf}
\end{center}
\end{columns}
\bottomnote{Finding the minimum of a high-dimensional function}
\end{frame}

% ==================== SECTION 4: GRADIENT DESCENT (Slides 19-28) ====================

\section{Gradient Descent: Finding the Minimum}


% Slide 19: The Optimization Problem
\begin{frame}[t]{The Optimization Problem}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{The Challenge}

Find:
$$\mathbf{W}^* = \arg\min_{\mathbf{W}} \mathcal{L}(\mathbf{W})$$

\vspace{0.5em}
\textbf{Difficulties:}
\begin{itemize}
\item Millions of dimensions
\item Non-convex landscape
\item No closed-form solution
\item Can't try all possibilities
\end{itemize}

\vspace{0.5em}
\textbf{We Need:}

An \textit{iterative} algorithm that gradually improves weights.

\column{0.48\textwidth}
\textbf{Possible Approaches}

\vspace{0.5em}
\textbf{Random Search:}
\begin{itemize}
\item Try random weights
\item Keep best so far
\item \textcolor{mlred}{Hopelessly slow}
\end{itemize}

\textbf{Grid Search:}
\begin{itemize}
\item Try all combinations
\item $10^{100}$ possibilities
\item \textcolor{mlred}{Impossible}
\end{itemize}

\textbf{Gradient-Based:}
\begin{itemize}
\item Use local slope information
\item Move toward improvement
\item \textcolor{mlgreen}{Tractable!}
\end{itemize}
\end{columns}
\bottomnote{How do we find the weights that minimize loss?}
\end{frame}

% Slide 20: The Blind Hiker Analogy
\begin{frame}[t]{The Blind Hiker Analogy}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{The Scenario}

Imagine you're:
\begin{itemize}
\item Blindfolded
\item On a mountainside
\item Trying to reach the valley
\item Can only feel the local slope
\end{itemize}

\vspace{0.5em}
\textbf{What Would You Do?}

\begin{enumerate}
\item Feel the ground around you
\item Determine which way is downhill
\item Take a step in that direction
\item Repeat until you reach a valley
\end{enumerate}

\column{0.48\textwidth}
\textbf{Neural Network Translation}

\vspace{0.5em}
\begin{tabular}{ll}
\toprule
\textbf{Hiker} & \textbf{Network} \\
\midrule
Position & Weights $\mathbf{W}$ \\
Altitude & Loss $\mathcal{L}$ \\
Slope & Gradient $\nabla \mathcal{L}$ \\
Step & Weight update \\
Valley & Minimum loss \\
\bottomrule
\end{tabular}

\vspace{0.5em}
\textbf{Key Insight:}

We don't need to see the whole landscape. Local slope is enough!
\end{columns}
\bottomnote{``You're blindfolded on a mountain. How do you find the valley?''}
\end{frame}

% Slide 21: Answer - Feel the Slope
\begin{frame}[t]{Answer: Feel the Slope}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{The Strategy}

\begin{enumerate}
\item Compute the slope (gradient)
\item Move opposite to the slope
\item Repeat until convergence
\end{enumerate}

\vspace{0.5em}
\textbf{Why Opposite?}
\begin{itemize}
\item Gradient points uphill
\item We want to go downhill
\item Move in negative gradient direction
\end{itemize}

\vspace{0.5em}
\textbf{The Update Rule:}

$$\mathbf{W} \leftarrow \mathbf{W} - \eta \nabla_{\mathbf{W}} \mathcal{L}$$

\column{0.48\textwidth}
\textbf{Gradient Descent Algorithm}

\vspace{0.5em}
\begin{enumerate}
\item Initialize $\mathbf{W}$ randomly
\item \textbf{repeat}:
\begin{enumerate}
\item[a.] Compute loss $\mathcal{L}(\mathbf{W})$
\item[b.] Compute gradient $\nabla \mathcal{L}$
\item[c.] Update: $\mathbf{W} \leftarrow \mathbf{W} - \eta \nabla \mathcal{L}$
\end{enumerate}
\item \textbf{until} convergence
\end{enumerate}

\vspace{0.5em}
$\eta$ = learning rate (step size)
\end{columns}
\bottomnote{Move in the direction that goes down}
\end{frame}

% Slide 22: Gradient Definition
\begin{frame}[t]{The Gradient: Direction of Steepest Ascent}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{What Is the Gradient?}

The gradient $\nabla \mathcal{L}$ is a vector of partial derivatives:

$$\nabla_{\mathbf{W}} \mathcal{L} = \begin{pmatrix} \frac{\partial \mathcal{L}}{\partial w_1} \\ \frac{\partial \mathcal{L}}{\partial w_2} \\ \vdots \\ \frac{\partial \mathcal{L}}{\partial w_n} \end{pmatrix}$$

\vspace{0.5em}
\textbf{Each Component:}

$\frac{\partial \mathcal{L}}{\partial w_i}$ = How much does loss change if we change $w_i$ slightly?

\column{0.48\textwidth}
\textbf{Properties}

\vspace{0.5em}
\textbf{Direction:}
\begin{itemize}
\item Points toward steepest increase
\item $-\nabla \mathcal{L}$ points toward steepest decrease
\end{itemize}

\textbf{Magnitude:}
\begin{itemize}
\item $\|\nabla \mathcal{L}\|$ = slope steepness
\item Near minimum: gradient $\approx 0$
\end{itemize}

\textbf{At a Minimum:}
$$\nabla \mathcal{L} = \mathbf{0}$$

No direction goes further down.
\end{columns}
\bottomnote{The gradient tells us which way is ``up''}
\end{frame}

% Slide 23: Gradient Descent Intuition
\begin{frame}[t]{Gradient Descent: Move Downhill}
\begin{center}
\includegraphics[width=0.52\textwidth]{../module3_training/charts/gradient_descent_contour/gradient_descent_contour.pdf}
\end{center}

% Quantlet branding (auto-generated)
\begin{tikzpicture}[remember picture,overlay]
% Logo (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.6cm,opacity=1.0] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/gradient_descent_contour}{\includegraphics[width=0.8cm]{../../quantlet_tools/logo/quantlet.png}}
};
% QR Code (clickable)
\node[anchor=south east,xshift=-1.3cm,yshift=0.6cm,opacity=0.8] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/gradient_descent_contour}{\includegraphics[width=0.6cm]{../module3_training/charts/gradient_descent_contour/qr_code.png}}
};
% URL text (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.2cm] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/gradient_descent_contour}{\tiny\texttt{\textcolor{gray}{gradient\_descent\_contour}}}
};
\end{tikzpicture}

\bottomnote{Step in the negative gradient direction}
\end{frame}

% Slide 24: Finance Parallel
\begin{frame}[t]{Finance Parallel: Portfolio Optimization}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Portfolio Adjustment}

Similar iterative process:
\begin{enumerate}
\item Evaluate current portfolio
\item Estimate sensitivities (``greeks'')
\item Adjust positions to reduce risk
\item Repeat periodically
\end{enumerate}

\vspace{0.5em}
\textbf{Delta Hedging:}
\begin{itemize}
\item Measure option delta
\item Adjust stock position
\item Move toward neutral
\end{itemize}

\column{0.48\textwidth}
\textbf{Comparison}

\vspace{0.5em}
\begin{tabular}{ll}
\toprule
\textbf{GD} & \textbf{Portfolio} \\
\midrule
Loss & Risk/Variance \\
Weights & Positions \\
Gradient & Sensitivities \\
Learning rate & Trading aggressiveness \\
Convergence & Optimal allocation \\
\bottomrule
\end{tabular}

\vspace{0.5em}
\textbf{Key Difference:}

Markets change continuously. Portfolios must adapt.

Neural networks train once (mostly).
\end{columns}
\bottomnote{Similar to iterative portfolio rebalancing}
\end{frame}

% Slide 25: The Learning Rate
\begin{frame}[t]{The Learning Rate: Step Size}
\begin{columns}[T]
\column{0.45\textwidth}
\textbf{The Hyperparameter $\eta$}

$$\mathbf{W} \leftarrow \mathbf{W} - \eta \nabla \mathcal{L}$$

\vspace{0.5em}
\textbf{$\eta$ Controls:}
\begin{itemize}
\item Size of each weight update
\item Speed of convergence
\item Stability of training
\end{itemize}

\vspace{0.5em}
\textbf{Typical Values:}
\begin{itemize}
\item $10^{-4}$ to $10^{-1}$
\item Often starts at 0.01 or 0.001
\item May decrease during training
\end{itemize}

\column{0.52\textwidth}
\begin{center}
\includegraphics[width=0.98\textwidth]{../module3_training/charts/learning_rate_effects/learning_rate_effects.pdf}
\end{center}
\end{columns}

% Quantlet branding (auto-generated)
\begin{tikzpicture}[remember picture,overlay]
% Logo (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.6cm,opacity=1.0] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/learning_rate_effects}{\includegraphics[width=0.8cm]{../../quantlet_tools/logo/quantlet.png}}
};
% QR Code (clickable)
\node[anchor=south east,xshift=-1.3cm,yshift=0.6cm,opacity=0.8] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/learning_rate_effects}{\includegraphics[width=0.6cm]{../module3_training/charts/learning_rate_effects/qr_code.png}}
};
% URL text (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.2cm] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/learning_rate_effects}{\tiny\texttt{\textcolor{gray}{learning\_rate\_effects}}}
};
\end{tikzpicture}

\bottomnote{Learning rate controls how far we move each step}
\end{frame}

% Slide 26: Learning Rate Too High
\begin{frame}[t]{Learning Rate Too High}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{The Problem}

When $\eta$ is too large:
\begin{itemize}
\item Steps overshoot the minimum
\item May jump to worse regions
\item Loss oscillates or explodes
\item Training diverges
\end{itemize}

\vspace{0.5em}
\textbf{Symptoms:}
\begin{itemize}
\item Loss goes up, not down
\item Loss becomes NaN
\item Weights grow very large
\item Erratic training curves
\end{itemize}

\column{0.48\textwidth}
\textbf{Finance Analogy}

\vspace{0.5em}
\textbf{Overtrading:}
\begin{itemize}
\item Adjusting positions too aggressively
\item Chasing every signal
\item Transaction costs accumulate
\item Portfolio becomes unstable
\end{itemize}

\vspace{0.5em}
\textbf{Solution:}

Reduce learning rate until stable.

\vspace{0.5em}
\textcolor{mlpurple}{\textbf{Rule of Thumb:}} If loss explodes, halve $\eta$.
\end{columns}
\bottomnote{Too big = overshoot the minimum}
\end{frame}

% Slide 27: Learning Rate Too Low
\begin{frame}[t]{Learning Rate Too Low}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{The Problem}

When $\eta$ is too small:
\begin{itemize}
\item Steps are tiny
\item Progress is slow
\item May get stuck in flat regions
\item Training takes forever
\end{itemize}

\vspace{0.5em}
\textbf{Symptoms:}
\begin{itemize}
\item Loss decreases very slowly
\item Many epochs with little improvement
\item May stop before reaching minimum
\item Wasted computation
\end{itemize}

\column{0.48\textwidth}
\textbf{Finance Analogy}

\vspace{0.5em}
\textbf{Underreacting:}
\begin{itemize}
\item Ignoring market signals
\item Missing opportunities
\item Portfolio drifts from target
\item Slow adaptation to regime changes
\end{itemize}

\vspace{0.5em}
\textbf{Solution:}

Increase learning rate or use adaptive methods.

\vspace{0.5em}
\textcolor{mlpurple}{\textbf{Modern Practice:}} Adaptive optimizers (Adam, RMSprop) adjust $\eta$ automatically.
\end{columns}
\bottomnote{Too small = converge too slowly}
\end{frame}

% Slide 28: Discussion Question 2
\begin{frame}[t]{Discussion Question}
\begin{center}
\Large
\textit{``In trading, what's analogous to learning rate? What happens if you adjust positions too aggressively or too conservatively?''}
\end{center}

\vspace{1em}
\textbf{Consider:}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Position Sizing:}
\begin{itemize}
\item How much to trade per signal
\item Kelly criterion vs. fractional Kelly
\item Risk management constraints
\end{itemize}

\column{0.48\textwidth}
\textbf{Rebalancing Frequency:}
\begin{itemize}
\item How often to adjust
\item Transaction cost vs. tracking error
\item Market impact considerations
\end{itemize}
\end{columns}

\vspace{0.5em}
\textcolor{mlpurple}{\textbf{Key Insight:}} Both trading and ML require balancing responsiveness against stability.
\bottomnote{Think-Pair-Share: 3 minutes}
\end{frame}

% ==================== SECTION 5: BACKPROPAGATION (Slides 29-38) ====================

\section{Backpropagation: Credit Assignment}


% Slide 29: The Attribution Problem
\begin{frame}[t]{The Attribution Problem}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{The Challenge}

We know:
\begin{itemize}
\item The output was wrong
\item We need to update weights
\item There are thousands of weights
\end{itemize}

\textbf{The Question:}

\begin{center}
\textit{Which weights caused the error?}
\end{center}

\vspace{0.5em}
\textbf{Credit Assignment:}

Attributing output error to individual weights deep in the network.

\column{0.48\textwidth}
\textbf{Why Is This Hard?}

\vspace{0.5em}
\textbf{Direct Attribution:}
\begin{itemize}
\item Output layer weights: clear influence
\item Hidden layer weights: indirect
\item Early layers: very indirect
\end{itemize}

\textbf{The Chain of Influence:}

$w_1 \rightarrow h_1 \rightarrow h_2 \rightarrow \cdots \rightarrow \hat{y} \rightarrow \mathcal{L}$

Each weight affects the loss through many intermediate steps.
\end{columns}
\bottomnote{The output was wrong. Which weights caused it?}
\end{frame}

% Slide 30: Finance Analogy
\begin{frame}[t]{Finance Analogy: Post-Trade Analysis}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Attribution in Trading}

A portfolio lost money. Why?

\begin{enumerate}
\item Macro call wrong?
\item Sector allocation off?
\item Stock selection bad?
\item Timing poor?
\item Execution costly?
\end{enumerate}

\vspace{0.5em}
\textbf{Performance Attribution:}
\begin{itemize}
\item Decompose returns by factor
\item Trace P\&L to decisions
\item Learn which calls were wrong
\end{itemize}

\column{0.48\textwidth}
\textbf{Neural Network Attribution}

\vspace{0.5em}
\begin{tabular}{ll}
\toprule
\textbf{Trading} & \textbf{Neural Net} \\
\midrule
Macro view & Early layers \\
Sector allocation & Hidden layers \\
Stock picks & Later layers \\
Final trades & Output \\
P\&L & Loss \\
\bottomrule
\end{tabular}

\vspace{0.5em}
\textbf{Backpropagation} is the neural network's performance attribution algorithm.
\end{columns}
\bottomnote{``Which decisions led to this P\&L?''}
\end{frame}

% Slide 31: Backpropagation Definition
\begin{frame}[t]{Backpropagation: Blame Assignment}
\begin{columns}[T]
\column{0.45\textwidth}
\textbf{The Algorithm}

Backpropagation computes $\frac{\partial \mathcal{L}}{\partial w}$ for every weight $w$ in the network.

\vspace{0.5em}
\textbf{Key Idea:}

Work backward from output to input, propagating error attribution.

\vspace{0.5em}
\textbf{Two Passes:}
\begin{enumerate}
\item \textbf{Forward Pass:} Compute outputs
\item \textbf{Backward Pass:} Compute gradients
\end{enumerate}

\vspace{0.5em}
\textbf{Efficiency:}

Computes ALL gradients in time proportional to one forward pass.

\column{0.52\textwidth}
\begin{center}
\includegraphics[width=0.98\textwidth]{../module3_training/charts/backprop_computational_graph/backprop_computational_graph.pdf}
\end{center}
\end{columns}

% Quantlet branding (auto-generated)
\begin{tikzpicture}[remember picture,overlay]
% Logo (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.6cm,opacity=1.0] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/backprop_computational_graph}{\includegraphics[width=0.8cm]{../../quantlet_tools/logo/quantlet.png}}
};
% QR Code (clickable)
\node[anchor=south east,xshift=-1.3cm,yshift=0.6cm,opacity=0.8] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/backprop_computational_graph}{\includegraphics[width=0.6cm]{../module3_training/charts/backprop_computational_graph/qr_code.png}}
};
% URL text (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.2cm] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/backprop_computational_graph}{\tiny\texttt{\textcolor{gray}{backprop\_computational\_graph}}}
};
\end{tikzpicture}

\bottomnote{Propagating error backward through the network}
\end{frame}

% Slide 32: The Chain Rule Intuition
\begin{frame}[t]{The Chain Rule: Intuition}
\begin{columns}[T]
\column{0.45\textwidth}
\textbf{The Core Mathematical Tool}

If $A$ affects $B$ and $B$ affects $C$:

$$\frac{\partial C}{\partial A} = \frac{\partial C}{\partial B} \cdot \frac{\partial B}{\partial A}$$

\vspace{0.5em}
\textbf{Example:}

Temperature $\rightarrow$ Ice cream sales $\rightarrow$ Profit

\vspace{0.5em}
How does temperature affect profit?

$$\frac{\partial \text{Profit}}{\partial \text{Temp}} = \frac{\partial \text{Profit}}{\partial \text{Sales}} \cdot \frac{\partial \text{Sales}}{\partial \text{Temp}}$$

\column{0.52\textwidth}
\begin{center}
\includegraphics[width=0.98\textwidth]{../module3_training/charts/chain_rule_visualization/chain_rule_visualization.pdf}
\end{center}
\end{columns}

% Quantlet branding (auto-generated)
\begin{tikzpicture}[remember picture,overlay]
% Logo (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.6cm,opacity=1.0] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/chain_rule_visualization}{\includegraphics[width=0.8cm]{../../quantlet_tools/logo/quantlet.png}}
};
% QR Code (clickable)
\node[anchor=south east,xshift=-1.3cm,yshift=0.6cm,opacity=0.8] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/chain_rule_visualization}{\includegraphics[width=0.6cm]{../module3_training/charts/chain_rule_visualization/qr_code.png}}
};
% URL text (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.2cm] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/chain_rule_visualization}{\tiny\texttt{\textcolor{gray}{chain\_rule\_visualization}}}
};
\end{tikzpicture}

\bottomnote{``If A affects B and B affects C, how does A affect C?''}
\end{frame}

% Slide 33: Finance Chain Example
\begin{frame}[t]{Finance Chain Example}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Chain of Effects}

\begin{center}
Fed Rate $\rightarrow$ Mortgages $\rightarrow$ Housing $\rightarrow$ Banks $\rightarrow$ Portfolio
\end{center}

\vspace{0.5em}
\textbf{How does Fed rate affect your portfolio?}

$$\frac{\partial \text{Portfolio}}{\partial \text{Fed}} = \frac{\partial P}{\partial B} \cdot \frac{\partial B}{\partial H} \cdot \frac{\partial H}{\partial M} \cdot \frac{\partial M}{\partial F}$$

\vspace{0.5em}
\textbf{Each Link:}
\begin{itemize}
\item Fed $\rightarrow$ Mortgages: rate sensitivity
\item Mortgages $\rightarrow$ Housing: demand elasticity
\item Housing $\rightarrow$ Banks: credit exposure
\item Banks $\rightarrow$ Portfolio: position size
\end{itemize}

\column{0.48\textwidth}
\textbf{Neural Network Parallel}

\vspace{0.5em}
\begin{tabular}{ll}
\toprule
\textbf{Finance} & \textbf{Neural Net} \\
\midrule
Fed rate & Input $x$ \\
Mortgages & Hidden layer 1 \\
Housing & Hidden layer 2 \\
Banks & Hidden layer 3 \\
Portfolio & Output \\
\bottomrule
\end{tabular}

\vspace{0.5em}
\textbf{Backprop does this automatically:}

Chains together all the local sensitivities to get the total effect of each input/weight on the loss.
\end{columns}
\bottomnote{Effects propagate through chains of influence}
\end{frame}

% Slide 34: Output Layer Gradients
\begin{frame}[t]{Backprop: Output Layer}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{At the Output}

For output weight $w^{(L)}$:

$$\frac{\partial \mathcal{L}}{\partial w^{(L)}} = \frac{\partial \mathcal{L}}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial z^{(L)}} \cdot \frac{\partial z^{(L)}}{\partial w^{(L)}}$$

\vspace{0.5em}
\textbf{Each Term:}
\begin{itemize}
\item $\frac{\partial \mathcal{L}}{\partial \hat{y}}$: How loss changes with output
\item $\frac{\partial \hat{y}}{\partial z^{(L)}}$: Activation derivative
\item $\frac{\partial z^{(L)}}{\partial w^{(L)}}$: Input from previous layer
\end{itemize}

\vspace{0.5em}
\textbf{For MSE + Sigmoid:}

$$\frac{\partial \mathcal{L}}{\partial w^{(L)}} = (\hat{y} - y) \cdot \hat{y}(1-\hat{y}) \cdot a^{(L-1)}$$

\column{0.48\textwidth}
\textbf{Output Error ($\delta^{(L)}$)}

\vspace{0.5em}
Define the ``error signal'':

$$\delta^{(L)} = \frac{\partial \mathcal{L}}{\partial z^{(L)}}$$

\vspace{0.5em}
For MSE loss + sigmoid:

$$\delta^{(L)} = (\hat{y} - y) \cdot \sigma'(z^{(L)})$$

\vspace{0.5em}
\textbf{Then:}

$$\frac{\partial \mathcal{L}}{\partial w^{(L)}} = \delta^{(L)} \cdot a^{(L-1)}$$

This is just error $\times$ input!
\end{columns}
\bottomnote{At the output, error attribution is straightforward}
\end{frame}

% Slide 35: Hidden Layer Gradients
\begin{frame}[t]{Backprop: Hidden Layers}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{The Key Insight}

Hidden layer error comes from downstream:

$$\delta^{(l)} = ((W^{(l+1)})^T \delta^{(l+1)}) \odot \sigma'(z^{(l)})$$

\vspace{0.5em}
\textbf{In Words:}
\begin{enumerate}
\item Take error from next layer ($\delta^{(l+1)}$)
\item Multiply by weights connecting to next layer
\item Scale by local activation derivative
\end{enumerate}

\vspace{0.5em}
\textbf{Error Flows Backward:}

Output $\rightarrow$ Last hidden $\rightarrow$ ... $\rightarrow$ First hidden

\column{0.48\textwidth}
\textbf{Why This Works}

\vspace{0.5em}
Chain rule connects layers:

$$\frac{\partial \mathcal{L}}{\partial z^{(l)}} = \sum_j \frac{\partial \mathcal{L}}{\partial z^{(l+1)}_j} \cdot \frac{\partial z^{(l+1)}_j}{\partial z^{(l)}}$$

\vspace{0.5em}
\textbf{Gradient for Hidden Weight:}

$$\frac{\partial \mathcal{L}}{\partial w^{(l)}} = \delta^{(l)} \cdot a^{(l-1)}$$

Same formula as output layer!
\end{columns}
\bottomnote{Hidden layer gradients require the chain rule}
\end{frame}

% Slide 36: The Complete Picture
\begin{frame}[t]{The Complete Training Loop}
\begin{columns}[T]
\column{0.45\textwidth}
\textbf{One Training Step}

\begin{enumerate}
\item \textbf{Forward Pass}
\begin{itemize}
\item Compute all activations
\item Get prediction $\hat{y}$
\end{itemize}

\item \textbf{Compute Loss}
\begin{itemize}
\item $\mathcal{L} = \ell(\hat{y}, y)$
\end{itemize}

\item \textbf{Backward Pass}
\begin{itemize}
\item Compute $\delta^{(L)}$ at output
\item Propagate backward to get all $\delta^{(l)}$
\item Compute all weight gradients
\end{itemize}

\item \textbf{Update Weights}
\begin{itemize}
\item $\mathbf{W} \leftarrow \mathbf{W} - \eta \nabla \mathcal{L}$
\end{itemize}
\end{enumerate}

\column{0.52\textwidth}
\begin{center}
\includegraphics[width=0.98\textwidth]{../module3_training/charts/gradient_flow_mlp/gradient_flow_mlp.pdf}
\end{center}
\end{columns}

% Quantlet branding (auto-generated)
\begin{tikzpicture}[remember picture,overlay]
% Logo (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.6cm,opacity=1.0] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/gradient_flow_mlp}{\includegraphics[width=0.8cm]{../../quantlet_tools/logo/quantlet.png}}
};
% QR Code (clickable)
\node[anchor=south east,xshift=-1.3cm,yshift=0.6cm,opacity=0.8] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/gradient_flow_mlp}{\includegraphics[width=0.6cm]{../module3_training/charts/gradient_flow_mlp/qr_code.png}}
};
% URL text (clickable)
\node[anchor=south east,xshift=-0.3cm,yshift=0.2cm] at (current page.south east) {
  \href{https://github.com/QuantLet/neural-networks-introduction/tree/main/gradient_flow_mlp}{\tiny\texttt{\textcolor{gray}{gradient\_flow\_mlp}}}
};
\end{tikzpicture}

\bottomnote{Forward pass, compute loss, backward pass, update weights}
\end{frame}

% Slide 37: Why "Backpropagation"?
\begin{frame}[t]{Why ``Backpropagation''?}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{The Name}

``Back-propagation of errors''

\vspace{0.5em}
\textbf{Information Flow:}

\textbf{Forward:}
\begin{itemize}
\item Data flows input $\rightarrow$ output
\item Activations computed layer by layer
\end{itemize}

\textbf{Backward:}
\begin{itemize}
\item Errors flow output $\rightarrow$ input
\item Gradients computed layer by layer
\end{itemize}

\vspace{0.5em}
\textbf{Symmetry:}

Each layer: one forward operation, one backward operation.

\column{0.48\textwidth}
\textbf{Historical Note}

\vspace{0.5em}
\textbf{The Algorithm:}
\begin{itemize}
\item Werbos (1974): first derivation
\item Rumelhart et al. (1986): popularized
\item Now standard in all deep learning
\end{itemize}

\textbf{Modern Perspective:}

Backprop is just automatic differentiation applied to neural networks.

\vspace{0.5em}
\textbf{Frameworks (PyTorch, TensorFlow):}

Compute gradients automatically -- you just specify the forward pass!
\end{columns}
\bottomnote{Error information flows from output to input}
\end{frame}

% Slide 38: Discussion Question 3
\begin{frame}[t]{Discussion Question}
\begin{center}
\Large
\textit{``Why do deeper networks make training harder? What happens to gradients as they flow backward through many layers?''}
\end{center}

\vspace{1em}
\textbf{Consider:}
\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Vanishing Gradients:}
\begin{itemize}
\item Sigmoid: max derivative 0.25
\item Through 10 layers: $0.25^{10}$
\item Early layers get tiny gradients
\item Learn extremely slowly
\end{itemize}

\column{0.48\textwidth}
\textbf{Exploding Gradients:}
\begin{itemize}
\item If derivatives $>$ 1
\item Gradients grow exponentially
\item Weights become huge
\item Training diverges
\end{itemize}
\end{columns}

\vspace{0.5em}
\textcolor{mlpurple}{\textbf{Solutions:}} ReLU, batch normalization, residual connections, careful initialization.
\bottomnote{Think-Pair-Share: 3 minutes}
\end{frame}

% ==================== SECTION 6: TRAINING DYNAMICS (Slides 39-46) ====================

\end{document}
